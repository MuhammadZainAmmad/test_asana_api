{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import asana        \n",
    "import pandas as pd \n",
    "import os\n",
    "\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('token.txt', 'r')\n",
    "token = f.readline()\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = asana.Client.access_token(token)\n",
    "\n",
    "# to surpress warnings\n",
    "client.headers = {'Asana-Enable': 'new_goal_memberships','Asana-Enable': \"new_user_task_lists\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a directory to store all the fetch results\n",
    "if not os.path.exists('./fetchedRecords'):\n",
    "    os.makedirs('./fetchedRecords')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fetching Workspaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "workspaces = list(client.workspaces.find_all())\n",
    "df_workspaces = pd.DataFrame(workspaces)\n",
    "df_workspaces.to_csv('./fetchedRecords/workspaces.csv', index= False)\n",
    "workspaces"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fetching Projects in a Workspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the workspace ID for fetching projects\n",
    "df_existedWorkspace = pd.read_csv('./fetchedRecords/workspace.csv')\n",
    "workspaceIDs = list(df_existedWorkspace['gid'])\n",
    "workspaceIDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "projects = list(client.projects.find_all(workspaceIDs[0]))\n",
    "df_projects = pd.DataFrame(projects)\n",
    "df_projects.to_csv('./fetchedRecords/projects.csv', index= False)\n",
    "projects"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fetching Sections in a Project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the project ID for fetching sections and tasks\n",
    "df_existedProjects = pd.read_csv('./fetchedRecords/projects.csv')\n",
    "projectIDs = list(df_existedProjects['gid'])\n",
    "projectIDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sections = list(client.sections.find_by_project(projectIDs[0]))\n",
    "df_sections = pd.DataFrame(sections)\n",
    "df_sections.to_csv('./fetchedRecords/sections.csv', index= False)\n",
    "sections"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fetching Tasks in a Project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fetching only modifies tasks (optimized approach) \n",
    "\n",
    "current_datetime = datetime.utcnow().isoformat()\n",
    "\n",
    "try: # file exists ==> some etl has already performed \n",
    "    df_tasks = pd.read_csv('./fetchedRecords/tasks.csv') # Assumed that file is always present\n",
    "    # print(f'Previous df\\n{df_tasks}\\n')    \n",
    "except FileNotFoundError: # etl running for the first time \n",
    "    df_tasks = pd.DataFrame(columns=['gid', 'name', 'resource_type', 'resource_subtype', 'etl_date_created', 'etl_date_modified'])\n",
    "    past_date = datetime(2000, 1, 1, 00, 00, 0000)\n",
    "    last_modified = past_date.strftime('%Y-%m-%dT%H:%M:%S.%f%z')\n",
    "else:\n",
    "    last_modified = df_tasks['etl_date_modified'].max()\n",
    "\n",
    "tasks = client.tasks.find_by_project(projectIDs[0], modified_since=last_modified)\n",
    "df_modifiedTasks = pd.DataFrame(tasks)\n",
    "    \n",
    "if len(df_modifiedTasks) == 0: # if no records are modifed since last_modified date \n",
    "    print('No modified records!!!')    \n",
    "else:\n",
    "    df_tasks['gid'] = df_tasks['gid'].astype(str)\n",
    "    df_tasks = df_tasks[~df_tasks['gid'].isin(df_modifiedTasks['gid'])]\n",
    "\n",
    "    # Adding etl_date_created and etl_date_modified columns in fetched df\n",
    "    df_modifiedTasks['etl_date_modified'] = current_datetime\n",
    "    df_modifiedTasks = df_modifiedTasks.merge(df_tasks[['gid', 'etl_date_created']], on='gid', how='left')\n",
    "    df_modifiedTasks['etl_date_created'].fillna(current_datetime, inplace=True)\n",
    "    # print(f'processed fetched df\\n{df_modifiedTasks}\\n')\n",
    "\n",
    "    # merging the two dfs\n",
    "    df_updatedTasks = pd.concat([df_tasks, df_modifiedTasks]).drop_duplicates(subset='gid', keep='last')\n",
    "    # print(f'final df\\n{df_updatedTasks}\\n')\n",
    "           \n",
    "    df_updatedTasks.to_csv(f'./fetchedRecords/tasks.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fetching task details "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_datetime = datetime.utcnow().isoformat()\n",
    "\n",
    "df_tasks = pd.read_csv('./fetchedRecords/tasks.csv')\n",
    "tasksDetails_list = []\n",
    "\n",
    "try: # file exists ==> some etl has already performed \n",
    "    df_existedTaskDetails = pd.read_csv('./fetchedRecords/taskDetails.csv') # Assumed that file is always present\n",
    "    # print(f'Previous df\\n{df_existedTaskDetails}\\n')    \n",
    "except FileNotFoundError: # etl running for the first time \n",
    "    # getting gids of all tasks \n",
    "    gids_tasksToFetch = list(df_tasks['gid'])\n",
    "    df_existedTaskDetails = pd.DataFrame(columns=['gid','etl_date_created', 'etl_date_modified'])\n",
    "else:\n",
    "    # getting the gids of tasks which are modifed after taskDetail etl previous run\n",
    "    df_taskAndTaskDetails = pd.merge(df_tasks, df_existedTaskDetails, on='gid', how = 'left', suffixes=('_df1', '_df2'))\n",
    "\n",
    "    gids_modifiedTasks = list(df_taskAndTaskDetails[df_taskAndTaskDetails['etl_date_modified_df1'] > df_taskAndTaskDetails['etl_date_modified_df2']]['gid'])\n",
    "    gids_newTasks = list(df_taskAndTaskDetails[df_taskAndTaskDetails['etl_date_modified_df2'].isnull()]['gid'])\n",
    "\n",
    "    gids_tasksToFetch = gids_modifiedTasks + gids_newTasks  \n",
    "\n",
    "if len(gids_tasksToFetch) == 0:\n",
    "    print('No modified records!!!')\n",
    "else:\n",
    "    df_tasks['gid'] = df_tasks['gid'].astype(str)\n",
    "    df_existedTaskDetails['gid'] = df_existedTaskDetails['gid'].astype(str)\n",
    "   \n",
    "    # calling API for the modified task details only\n",
    "    for task_gid in gids_tasksToFetch:\n",
    "        task = client.tasks.get_task(str(task_gid))\n",
    "        tasksDetails_list.append(task)\n",
    "    df_newTaskDetails = pd.DataFrame(tasksDetails_list)\n",
    "\n",
    "    # Adding etl_date_created and etl_date_modified columns in fetched df\n",
    "    df_newTaskDetails['etl_date_modified'] = current_datetime\n",
    "    df_newTaskDetails = df_newTaskDetails.merge(df_existedTaskDetails[['gid', 'etl_date_created']], on='gid', how='left')\n",
    "    df_newTaskDetails['etl_date_created'].fillna(current_datetime, inplace=True)    \n",
    "    # print(f'processed fetched df\\n{df_modifiedTasks.head()}\\n')\n",
    "\n",
    "    # merging the two dfs\n",
    "    df_updatedTaskDetails = pd.concat([df_existedTaskDetails, df_newTaskDetails]).drop_duplicates(subset='gid', keep='last')\n",
    "    # print(f'final df\\n{df_updatedTaskDetails.head()}\\n')\n",
    "     \n",
    "    df_updatedTaskDetails.to_csv(f'./fetchedRecords/taskDetails.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fetching users in a workspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gid</th>\n",
       "      <th>name</th>\n",
       "      <th>resource_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1204862567026473</td>\n",
       "      <td>My workspace</td>\n",
       "      <td>workspace</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                gid          name resource_type\n",
       "0  1204862567026473  My workspace     workspace"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_workspaces = pd.read_csv('./fetchedRecords/workspaces.csv')\n",
    "df_workspaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Electro Store\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\asana\\client.py:156: UserWarning: This request is affected by the \"new_goal_memberships\" deprecation. Please visit this url for more info: https://forum.asana.com/t/launched-team-sharing-for-goals/378601\n",
      "Adding \"new_goal_memberships\" to your \"Asana-Enable\" or \"Asana-Disable\" header will opt in/out to this deprecation and suppress this warning.\n",
      "  warnings.warn(message)\n"
     ]
    }
   ],
   "source": [
    "user_records = []\n",
    "for ws_id in list(df_workspaces['gid']):\n",
    "    users = client.users.get_users({'param': 'value', 'param': 'value'}, workspace= ws_id, opt_pretty=True)\n",
    "    for user in users:\n",
    "        id = user['gid']\n",
    "        name = user['name']\n",
    "        resType = user['resource_type']\n",
    "    user_records.append([id, name, resType, ws_id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_userRecords = pd.DataFrame(user_records)\n",
    "\n",
    "tableHeaders = ['gid', 'user_name', 'resourceType', 'workspace_gid']\n",
    "df_userRecords.columns = tableHeaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_userRecords.to_csv('./fetchedRecords/userRecords.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
